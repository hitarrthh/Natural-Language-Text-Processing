{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1c9d5dd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9d5dd3",
        "outputId": "4e5b4522-20e1-4b2f-cf90-50049155d103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "spanish_stopwords = list(stopwords.words('spanish'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57db4ad0",
      "metadata": {
        "id": "57db4ad0"
      },
      "source": [
        "\n",
        "## Method-1: Dictionary-based / Knowledge-based (Lesk Algorithm)\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2f4e1fce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4e1fce",
        "outputId": "6b051c2e-0a62-493a-e771-0ffce2ede1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best sense: Synset('depository_financial_institution.n.01')\n",
            "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
          ]
        }
      ],
      "source": [
        "def lesk_algorithm(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"I went to the bank to deposit my money\"\n",
        "ambiguous = \"bank\"\n",
        "sense = lesk_algorithm(sentence, ambiguous)\n",
        "print(\"Best sense:\", sense)\n",
        "print(\"Definition:\", sense.definition())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "E_l6ScXa8bZ6"
      },
      "id": "E_l6ScXa8bZ6"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "mHytx-WDIas8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHytx-WDIas8",
        "outputId": "ae0c53a0-0444-4ff5-caa0-4f610246d8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best sense: bank.n.09\n",
            "Definition: a building in which the business of banking transacted\n"
          ]
        }
      ],
      "source": [
        "def lesk_algorithm(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "def lesk_algorithm_spanish(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    # Try to find a sense at any cost\n",
        "    for sense in wn.synsets(ambiguous_word, lang='spa'):\n",
        "        best_sense = sense\n",
        "        break\n",
        "    # If no sense found in Spanish Wordnet, fallback to English\n",
        "    if best_sense is None:\n",
        "        for sense in wn.synsets(ambiguous_word):\n",
        "            best_sense = sense\n",
        "            break\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"Fui al banco a depositar mi dinero.\"\n",
        "ambiguous = \"banco\"\n",
        "sense = lesk_algorithm_spanish(sentence, ambiguous)\n",
        "\n",
        "if sense:\n",
        "    print(\"\\nBest sense:\", sense.name())\n",
        "    print(\"Definition:\", sense.definition())\n",
        "else:\n",
        "    print(\"\\nNo sense found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1351b7e",
      "metadata": {
        "id": "e1351b7e"
      },
      "source": [
        "\n",
        "## Method-2: Supervised Methods\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "52d06f26",
      "metadata": {
        "id": "52d06f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd787675-d8f4-4e01-a262-9ffeeb5ca4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "🎯 Best sense for example sentence:\n",
            "🔹 Predicted Sense: River Bank\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"I deposited money at the bank\", 0),\n",
        "    (\"The bank approved my loan\", 0),\n",
        "    (\"The river bank was flooded\", 1),\n",
        "    (\"They had a picnic on the bank of the river\", 1),\n",
        "    (\"She went to the bank to open an account\", 0),\n",
        "    (\"We sat by the bank enjoying the view\", 1)\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "example = [\"I need to visit the bank for a transaction\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Financial Institution\", 1: \"River Bank\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\n🎯 Best sense for example sentence:\")\n",
        "print(\"🔹 Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "seem5iTJ8gPd"
      },
      "id": "seem5iTJ8gPd"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bnIj4GP_IfJu",
      "metadata": {
        "id": "bnIj4GP_IfJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7d0614-b2e2-494d-e48e-918002b9db10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Clasificación del Modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "🎯 Mejor sentido para la oración de ejemplo:\n",
            "🔹 Sentido Predicho: Institución Financiera\n",
            "📖 Definición: a building in which the business of banking transacted\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"Deposité dinero en el banco\", 0),\n",
        "    (\"El banco aprobó mi préstamo\", 0),\n",
        "    (\"La orilla del río estaba inundada\", 1),\n",
        "    (\"Hicieron un picnic en la orilla del río\", 1),\n",
        "    (\"Ella fue al banco para abrir una cuenta\", 0),\n",
        "    (\"Nos sentamos junto al banco disfrutando la vista\", 1)\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\n📊 Clasificación del Modelo:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "example = [\"Necesito ir al banco para una transacción\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Institución Financiera\", 1: \"Orilla del Río\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "def get_sense_definition(word, sense_label):\n",
        "    synsets = wn.synsets(word, lang=\"spa\")\n",
        "\n",
        "    if not synsets:\n",
        "        return \"⚠️ No se encontró una definición en WordNet.\"\n",
        "\n",
        "    if sense_label == 0:\n",
        "        for syn in synsets:\n",
        "            if \"banco\" in syn.name() and \"financiera\" in syn.definition():\n",
        "                return syn.definition()\n",
        "\n",
        "    if sense_label == 1:\n",
        "        for syn in synsets:\n",
        "            if \"banco\" in syn.name() and \"río\" in syn.definition():\n",
        "                return syn.definition()\n",
        "\n",
        "    return synsets[0].definition()\n",
        "\n",
        "definition = get_sense_definition(\"banco\", pred[0])\n",
        "\n",
        "print(\"\\n🎯 Mejor sentido para la oración de ejemplo:\")\n",
        "print(\"🔹 Sentido Predicho:\", predicted_sense)\n",
        "print(\"📖 Definición:\", definition)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vq2GmnIVIhfK",
      "metadata": {
        "id": "vq2GmnIVIhfK"
      },
      "source": [
        "#Semi-supervised Methods (Bootstrapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "UKzRes97IoUz",
      "metadata": {
        "id": "UKzRes97IoUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d57435d-7867-4c31-f89b-443cdde66264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Initial Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "🌀 Iteration 1 of Bootstrapping\n",
            "✅ Added: 'The river bank was scenic and calm' → Predicted as Financial Institution (Confidence: 0.85)\n",
            "📈 Retrained with 5 total samples.\n",
            "\n",
            "🌀 Iteration 2 of Bootstrapping\n",
            "⚠️ No high-confidence samples to add. Stopping bootstrapping.\n",
            "\n",
            "🎯 Final Training Data Size: 5\n",
            "\n",
            "🎯 Best sense for example sentence:\n",
            "🔹 Predicted Sense: Financial Institution\n"
          ]
        }
      ],
      "source": [
        "labeled_data = [\n",
        "    (\"I deposited money at the bank\", 0),\n",
        "    (\"The bank approved my loan\", 0),\n",
        "    (\"The river bank was flooded\", 1),\n",
        "    (\"They had a picnic on the bank of the river\", 1)\n",
        "]\n",
        "\n",
        "unlabeled_texts = [\n",
        "    \"She went to the bank to open an account\",\n",
        "    \"We enjoyed the view by the bank\",\n",
        "    \"The bank offers great interest rates\",\n",
        "    \"The river bank was scenic and calm\"\n",
        "]\n",
        "\n",
        "labeled_texts, labels = zip(*labeled_data)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(labeled_texts, labels)\n",
        "\n",
        "y_pred = model.predict(labeled_texts)\n",
        "print(\"\\n📊 Initial Model Classification Report:\")\n",
        "print(classification_report(labels, y_pred))\n",
        "\n",
        "threshold = 0.8\n",
        "new_labeled_texts = list(labeled_texts)\n",
        "new_labels = list(labels)\n",
        "\n",
        "for iteration in range(3):\n",
        "    print(f\"\\n🌀 Iteration {iteration+1} of Bootstrapping\")\n",
        "\n",
        "    predictions = model.predict_proba(unlabeled_texts)\n",
        "    to_add = []\n",
        "    remaining_texts = []\n",
        "\n",
        "    for text, probs in zip(unlabeled_texts, predictions):\n",
        "        max_prob = np.max(probs)\n",
        "        pred_label = np.argmax(probs)\n",
        "\n",
        "        if max_prob >= threshold:\n",
        "            to_add.append((text, pred_label))\n",
        "            print(f\"✅ Added: '{text}' → Predicted as {'Financial Institution' if pred_label==0 else 'River Bank'} (Confidence: {max_prob:.2f})\")\n",
        "        else:\n",
        "            remaining_texts.append(text)\n",
        "\n",
        "    if not to_add:\n",
        "        print(\"⚠️ No high-confidence samples to add. Stopping bootstrapping.\")\n",
        "        break\n",
        "\n",
        "    for text, label in to_add:\n",
        "        new_labeled_texts.append(text)\n",
        "        new_labels.append(label)\n",
        "\n",
        "    unlabeled_texts = remaining_texts\n",
        "    model.fit(new_labeled_texts, new_labels)\n",
        "    print(f\"📈 Retrained with {len(new_labeled_texts)} total samples.\")\n",
        "\n",
        "print(\"\\n🎯 Final Training Data Size:\", len(new_labeled_texts))\n",
        "\n",
        "example = [\"I need to visit the bank for a transaction\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Financial Institution\", 1: \"River Bank\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\n🎯 Best sense for example sentence:\")\n",
        "print(\"🔹 Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "iIhehulF8yCC"
      },
      "id": "iIhehulF8yCC"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "mhQBwRqgIouH",
      "metadata": {
        "id": "mhQBwRqgIouH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d78b5bd-54ae-4e30-a212-cf509e7128fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Informe de Clasificación Inicial del Modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "🌀 Iteración 1 de Bootstrapping\n",
            "✅ Añadido: 'El banco ofrece tasas de interés atractivas' → Predicho como Institución Financiera (Confianza: 0.86)\n",
            "✅ Añadido: 'La orilla del río era hermosa y tranquila' → Predicho como Orilla del Río (Confianza: 0.87)\n",
            "📈 Reentrenado con 6 muestras en total.\n",
            "\n",
            "🌀 Iteración 2 de Bootstrapping\n",
            "⚠️ No hay muestras de alta confianza para agregar. Deteniendo el bootstrapping.\n",
            "\n",
            "🎯 Tamaño final del conjunto de entrenamiento: 6\n",
            "\n",
            "🎯 Mejor sentido para la oración de ejemplo:\n",
            "🔹 Sentido Predicho: Institución Financiera\n"
          ]
        }
      ],
      "source": [
        "labeled_data = [\n",
        "    (\"Deposité dinero en el banco\", 0),\n",
        "    (\"El banco aprobó mi préstamo\", 0),\n",
        "    (\"La orilla del río estaba inundada\", 1),\n",
        "    (\"Hicieron un picnic en la orilla del río\", 1)\n",
        "]\n",
        "\n",
        "unlabeled_texts = [\n",
        "    \"Ella fue al banco para abrir una cuenta\",\n",
        "    \"Disfrutamos la vista junto al banco\",\n",
        "    \"El banco ofrece tasas de interés atractivas\",\n",
        "    \"La orilla del río era hermosa y tranquila\"\n",
        "]\n",
        "\n",
        "labeled_texts, labels = zip(*labeled_data)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(labeled_texts, labels)\n",
        "y_pred = model.predict(labeled_texts)\n",
        "print(\"\\n📊 Informe de Clasificación Inicial del Modelo:\")\n",
        "print(classification_report(labels, y_pred))\n",
        "threshold = 0.8\n",
        "new_labeled_texts = list(labeled_texts)\n",
        "new_labels = list(labels)\n",
        "\n",
        "for iteration in range(3):\n",
        "    print(f\"\\n🌀 Iteración {iteration+1} de Bootstrapping\")\n",
        "\n",
        "    predictions = model.predict_proba(unlabeled_texts)\n",
        "    to_add = []\n",
        "    remaining_texts = []\n",
        "\n",
        "    for text, probs in zip(unlabeled_texts, predictions):\n",
        "        max_prob = np.max(probs)\n",
        "        pred_label = np.argmax(probs)\n",
        "\n",
        "        if max_prob >= threshold:\n",
        "            to_add.append((text, pred_label))\n",
        "            print(f\"✅ Añadido: '{text}' → Predicho como {'Institución Financiera' if pred_label==0 else 'Orilla del Río'} (Confianza: {max_prob:.2f})\")\n",
        "        else:\n",
        "            remaining_texts.append(text)\n",
        "\n",
        "    if not to_add:\n",
        "        print(\"⚠️ No hay muestras de alta confianza para agregar. Deteniendo el bootstrapping.\")\n",
        "        break\n",
        "    for text, label in to_add:\n",
        "        new_labeled_texts.append(text)\n",
        "        new_labels.append(label)\n",
        "    unlabeled_texts = remaining_texts\n",
        "\n",
        "    model.fit(new_labeled_texts, new_labels)\n",
        "    print(f\"📈 Reentrenado con {len(new_labeled_texts)} muestras en total.\")\n",
        "\n",
        "print(\"\\n🎯 Tamaño final del conjunto de entrenamiento:\", len(new_labeled_texts))\n",
        "\n",
        "example = [\"Necesito ir al banco para una transacción\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Institución Financiera\", 1: \"Orilla del Río\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\n🎯 Mejor sentido para la oración de ejemplo:\")\n",
        "print(\"🔹 Sentido Predicho:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0FvNNLcNItyu",
      "metadata": {
        "id": "0FvNNLcNItyu"
      },
      "source": [
        "#Unsupervised Methods (Clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-1 (English)"
      ],
      "metadata": {
        "id": "YQ9V_efG9Dxp"
      },
      "id": "YQ9V_efG9Dxp"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "-NAv26nnIuoX",
      "metadata": {
        "id": "-NAv26nnIuoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128ee7ad-5b3e-4cd2-a866-fba8993cdbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Clustering-based Word Sense Disambiguation:\n",
            "Cluster 0 (Financial Institution): I deposited money at the bank\n",
            "Cluster 0 (Financial Institution): The bank approved my loan\n",
            "Cluster 0 (Financial Institution): The river bank was flooded\n",
            "Cluster 0 (Financial Institution): They had a picnic on the bank of the river\n",
            "Cluster 1 (Financial Institution): She went to the bank to open an account\n",
            "Cluster 0 (Financial Institution): We enjoyed the view by the bank\n",
            "\n",
            "🎯 Best sense for example sentence:\n",
            "🔹 Predicted Sense: Financial Institution\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"I deposited money at the bank\",\n",
        "    \"The bank approved my loan\",\n",
        "    \"The river bank was flooded\",\n",
        "    \"They had a picnic on the bank of the river\",\n",
        "    \"She went to the bank to open an account\",\n",
        "    \"We enjoyed the view by the bank\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "num_clusters = 2\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "\n",
        "cluster_sense_map = {}\n",
        "for i in range(num_clusters):\n",
        "    representative_sentence = sentences[labels.tolist().index(i)]\n",
        "    if \"loan\" in representative_sentence or \"deposit\" in representative_sentence or \"account\" in representative_sentence:\n",
        "        cluster_sense_map[i] = \"Financial Institution\"\n",
        "    else:\n",
        "        cluster_sense_map[i] = \"River Bank\"\n",
        "\n",
        "print(\"\\n🔍 Clustering-based Word Sense Disambiguation:\")\n",
        "for sentence, cluster in zip(sentences, labels):\n",
        "    print(f\"Cluster {cluster} ({cluster_sense_map[cluster]}): {sentence}\")\n",
        "\n",
        "example_sentence = [\"I need to visit the bank for a transaction\"]\n",
        "example_vector = vectorizer.transform(example_sentence)\n",
        "predicted_cluster = kmeans.predict(example_vector)[0]\n",
        "predicted_sense = cluster_sense_map[predicted_cluster]\n",
        "\n",
        "print(\"\\n🎯 Best sense for example sentence:\")\n",
        "print(\"🔹 Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "eVr_y14O9CT7"
      },
      "id": "eVr_y14O9CT7"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ItWzHBMJIvA1",
      "metadata": {
        "id": "ItWzHBMJIvA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddedb6a-21ff-40ed-9427-dcc0d6944fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Desambiguación de palabras basada en Clustering:\n",
            "Cluster 1 (Sail (Vela de Barco)): Encendí una vela en la mesa\n",
            "Cluster 1 (Sail (Vela de Barco)): Apagó la vela antes de dormir\n",
            "Cluster 0 (Sail (Vela de Barco)): El viento llenó la vela del barco\n",
            "Cluster 1 (Sail (Vela de Barco)): El marinero ajustó la vela para navegar mejor\n",
            "Cluster 1 (Sail (Vela de Barco)): Colocaron una vela en el pastel de cumpleaños\n",
            "Cluster 1 (Sail (Vela de Barco)): La vela del velero era enorme\n",
            "\n",
            "🎯 Mejor sentido para la oración de ejemplo:\n",
            "🔹 Sentido Predicho: Sail (Vela de Barco)\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"Encendí una vela en la mesa\",\n",
        "    \"Apagó la vela antes de dormir\",\n",
        "    \"El viento llenó la vela del barco\",\n",
        "    \"El marinero ajustó la vela para navegar mejor\",\n",
        "    \"Colocaron una vela en el pastel de cumpleaños\",\n",
        "    \"La vela del velero era enorme\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=spanish_stopwords)\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "num_clusters = 2\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "cluster_sense_map = {}\n",
        "for i in range(num_clusters):\n",
        "    representative_sentence = sentences[labels.tolist().index(i)]\n",
        "    if \"encendí\" in representative_sentence or \"apagó\" in representative_sentence or \"pastel\" in representative_sentence:\n",
        "        cluster_sense_map[i] = \"Candle (Veladora)\"\n",
        "    else:\n",
        "        cluster_sense_map[i] = \"Sail (Vela de Barco)\"\n",
        "\n",
        "print(\"\\n🔍 Desambiguación de palabras basada en Clustering:\")\n",
        "for sentence, cluster in zip(sentences, labels):\n",
        "    print(f\"Cluster {cluster} ({cluster_sense_map[cluster]}): {sentence}\")\n",
        "\n",
        "example_sentence = [\"Puse una vela en la mesa para iluminar\"]\n",
        "example_vector = vectorizer.transform(example_sentence)\n",
        "predicted_cluster = kmeans.predict(example_vector)[0]\n",
        "predicted_sense = cluster_sense_map[predicted_cluster]\n",
        "\n",
        "print(\"\\n🎯 Mejor sentido para la oración de ejemplo:\")\n",
        "print(\"🔹 Sentido Predicho:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8662fa",
      "metadata": {
        "id": "3f8662fa"
      },
      "source": [
        "\n",
        "## Method-5: Enhanced Lesk Algorithm (Extended Lesk)\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "661804cd",
      "metadata": {
        "id": "661804cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5237ca-5607-4ee8-b6bf-5ee97f37fd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Lesk - Best sense: Synset('depository_financial_institution.n.01')\n",
            "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
          ]
        }
      ],
      "source": [
        "def enhanced_lesk(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        for ex in sense.examples():\n",
        "            signature.update(word_tokenize(ex))\n",
        "        for lemma in sense.lemmas():\n",
        "            signature.add(lemma.name())\n",
        "\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"I went to the bank to deposit my money\"\n",
        "ambiguous = \"bank\"\n",
        "sense = enhanced_lesk(sentence, ambiguous)\n",
        "print(\"Enhanced Lesk - Best sense:\", sense)\n",
        "print(\"Definition:\", sense.definition())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "fUBzoCZb9ccd"
      },
      "id": "fUBzoCZb9ccd"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "U6cvLugBI1g5",
      "metadata": {
        "id": "U6cvLugBI1g5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451ca801-8d84-4f22-d5e8-1733bd7585c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Lesk - Mejor sentido: Synset('sierra.n.01')\n",
            "Definición: a range of mountains (usually with jagged peaks and irregular outline)\n"
          ]
        }
      ],
      "source": [
        "def enhanced_lesk_spanish(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word, lang=\"spa\"):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        for ex in sense.examples():\n",
        "            signature.update(word_tokenize(ex))\n",
        "        for lemma in sense.lemmas():\n",
        "            signature.add(lemma.name())\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"Usé la sierra para cortar la madera\"\n",
        "ambiguous = \"sierra\"\n",
        "sense = enhanced_lesk_spanish(sentence, ambiguous)\n",
        "print(\"Enhanced Lesk - Mejor sentido:\", sense)\n",
        "if sense:\n",
        "    print(\"Definición:\", sense.definition())\n",
        "else:\n",
        "    print(\"⚠️ No se encontró una definición.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5df535f",
      "metadata": {
        "id": "a5df535f"
      },
      "source": [
        "\n",
        "## Method-6: Word Embeddings Based WSD\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f462cc36",
      "metadata": {
        "id": "f462cc36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2a9c1b-95f7-4df9-c542-1bbd29b589dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings WSD - Best Sense: Synset('bark.n.02')\n",
            "Definition: a noise resembling the bark of a dog\n"
          ]
        }
      ],
      "source": [
        "def get_signature_text_english(sense):\n",
        "    text = sense.definition() + \" \" + \" \".join(sense.examples()) + \" \" + \" \".join([lemma.name() for lemma in sense.lemmas()])\n",
        "    return text\n",
        "\n",
        "def embeddings_wsd_english(context_sentence, ambiguous_word):\n",
        "    senses = wn.synsets(ambiguous_word)\n",
        "    if not senses:\n",
        "        return None\n",
        "\n",
        "    corpus = [context_sentence] + [get_signature_text_english(sense) for sense in senses]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    context_vector = vectors[0]\n",
        "    sense_vectors = vectors[1:]\n",
        "\n",
        "    similarities = cosine_similarity(context_vector, sense_vectors)[0]\n",
        "    best_sense_index = similarities.argmax()\n",
        "    return senses[best_sense_index]\n",
        "\n",
        "sentence = \"The dog started to bark loudly\"\n",
        "ambiguous = \"bark\"\n",
        "sense = embeddings_wsd_english(sentence, ambiguous)\n",
        "\n",
        "print(\"Embeddings WSD - Best Sense:\", sense)\n",
        "print(\"Definition:\", sense.definition() if sense else \"⚠️ No definition found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "CpcqxB4u9iEq"
      },
      "id": "CpcqxB4u9iEq"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Ud7L_8McI5Kr",
      "metadata": {
        "id": "Ud7L_8McI5Kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9d7d42-cdfa-4a83-a45a-87bd95c2794b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings WSD - Mejor sentido: Synset('vigil.n.02')\n",
            "Definición: the rite of staying awake for devotional purposes (especially on the eve of a religious festival)\n"
          ]
        }
      ],
      "source": [
        "def get_signature_text_spanish(sense):\n",
        "    text = sense.definition() + \" \" + \" \".join(sense.examples()) + \" \" + \" \".join([lemma.name() for lemma in sense.lemmas()])\n",
        "    return text\n",
        "\n",
        "def embeddings_wsd_spanish(context_sentence, ambiguous_word):\n",
        "    senses = wn.synsets(ambiguous_word, lang=\"spa\")\n",
        "    if not senses:\n",
        "        return None\n",
        "\n",
        "    corpus = [context_sentence] + [get_signature_text_spanish(sense) for sense in senses]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    context_vector = vectors[0]\n",
        "    sense_vectors = vectors[1:]\n",
        "\n",
        "    similarities = cosine_similarity(context_vector, sense_vectors)[0]\n",
        "    best_sense_index = similarities.argmax()\n",
        "    return senses[best_sense_index]\n",
        "\n",
        "sentence = \"Encendí una vela en la mesa\"\n",
        "ambiguous = \"vela\"\n",
        "sense = embeddings_wsd_spanish(sentence, ambiguous)\n",
        "\n",
        "print(\"Embeddings WSD - Mejor sentido:\", sense)\n",
        "print(\"Definición:\", sense.definition() if sense else \"⚠️ No se encontró una definición.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "Word Sense Disambiguation (WSD) is a crucial task in Natural Language Processing (NLP) that helps determine the correct meaning of an ambiguous word based on its context. In this discussion, we explored multiple approaches to WSD, including supervised, semi-supervised, and unsupervised methods. The Lesk algorithm and its enhanced versions leveraged word definitions and context overlap, while the supervised approach used machine learning models like Support Vector Machines (SVMs) trained on labeled datasets. We also implemented semi-supervised bootstrapping, which expanded the training set by incorporating high-confidence predictions. The unsupervised clustering method applied TF-IDF vectorization and K-Means to group sentences based on similar meanings, offering a purely data-driven approach. Additionally, we experimented with word embeddings-based WSD using cosine similarity to compare contextual and definition vectors without relying on labeled data. Each method has its strengths—rule-based approaches are interpretable but limited by dictionary coverage, supervised methods perform well with sufficient labeled data, and unsupervised techniques offer scalability but may require fine-tuning. Our final consolidated setup ensures that all necessary libraries and datasets are available for seamless execution of any WSD method. These techniques collectively contribute to improving machine understanding of ambiguous words, which is essential for applications like machine translation, information retrieval, and text analysis."
      ],
      "metadata": {
        "id": "Bn4M7-9y9rNA"
      },
      "id": "Bn4M7-9y9rNA"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}