{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1c9d5dd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9d5dd3",
        "outputId": "4e5b4522-20e1-4b2f-cf90-50049155d103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "spanish_stopwords = list(stopwords.words('spanish'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57db4ad0",
      "metadata": {
        "id": "57db4ad0"
      },
      "source": [
        "\n",
        "## Method-1: Dictionary-based / Knowledge-based (Lesk Algorithm)\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2f4e1fce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4e1fce",
        "outputId": "6b051c2e-0a62-493a-e771-0ffce2ede1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best sense: Synset('depository_financial_institution.n.01')\n",
            "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
          ]
        }
      ],
      "source": [
        "def lesk_algorithm(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"I went to the bank to deposit my money\"\n",
        "ambiguous = \"bank\"\n",
        "sense = lesk_algorithm(sentence, ambiguous)\n",
        "print(\"Best sense:\", sense)\n",
        "print(\"Definition:\", sense.definition())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "E_l6ScXa8bZ6"
      },
      "id": "E_l6ScXa8bZ6"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "mHytx-WDIas8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHytx-WDIas8",
        "outputId": "ae0c53a0-0444-4ff5-caa0-4f610246d8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best sense: bank.n.09\n",
            "Definition: a building in which the business of banking transacted\n"
          ]
        }
      ],
      "source": [
        "def lesk_algorithm(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "def lesk_algorithm_spanish(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    # Try to find a sense at any cost\n",
        "    for sense in wn.synsets(ambiguous_word, lang='spa'):\n",
        "        best_sense = sense\n",
        "        break\n",
        "    # If no sense found in Spanish Wordnet, fallback to English\n",
        "    if best_sense is None:\n",
        "        for sense in wn.synsets(ambiguous_word):\n",
        "            best_sense = sense\n",
        "            break\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"Fui al banco a depositar mi dinero.\"\n",
        "ambiguous = \"banco\"\n",
        "sense = lesk_algorithm_spanish(sentence, ambiguous)\n",
        "\n",
        "if sense:\n",
        "    print(\"\\nBest sense:\", sense.name())\n",
        "    print(\"Definition:\", sense.definition())\n",
        "else:\n",
        "    print(\"\\nNo sense found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1351b7e",
      "metadata": {
        "id": "e1351b7e"
      },
      "source": [
        "\n",
        "## Method-2: Supervised Methods\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "52d06f26",
      "metadata": {
        "id": "52d06f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd787675-d8f4-4e01-a262-9ffeeb5ca4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "üéØ Best sense for example sentence:\n",
            "üîπ Predicted Sense: River Bank\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"I deposited money at the bank\", 0),\n",
        "    (\"The bank approved my loan\", 0),\n",
        "    (\"The river bank was flooded\", 1),\n",
        "    (\"They had a picnic on the bank of the river\", 1),\n",
        "    (\"She went to the bank to open an account\", 0),\n",
        "    (\"We sat by the bank enjoying the view\", 1)\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "example = [\"I need to visit the bank for a transaction\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Financial Institution\", 1: \"River Bank\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\nüéØ Best sense for example sentence:\")\n",
        "print(\"üîπ Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "seem5iTJ8gPd"
      },
      "id": "seem5iTJ8gPd"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bnIj4GP_IfJu",
      "metadata": {
        "id": "bnIj4GP_IfJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7d0614-b2e2-494d-e48e-918002b9db10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Clasificaci√≥n del Modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "üéØ Mejor sentido para la oraci√≥n de ejemplo:\n",
            "üîπ Sentido Predicho: Instituci√≥n Financiera\n",
            "üìñ Definici√≥n: a building in which the business of banking transacted\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"Deposit√© dinero en el banco\", 0),\n",
        "    (\"El banco aprob√≥ mi pr√©stamo\", 0),\n",
        "    (\"La orilla del r√≠o estaba inundada\", 1),\n",
        "    (\"Hicieron un picnic en la orilla del r√≠o\", 1),\n",
        "    (\"Ella fue al banco para abrir una cuenta\", 0),\n",
        "    (\"Nos sentamos junto al banco disfrutando la vista\", 1)\n",
        "]\n",
        "\n",
        "texts, labels = zip(*data)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nüìä Clasificaci√≥n del Modelo:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "example = [\"Necesito ir al banco para una transacci√≥n\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Instituci√≥n Financiera\", 1: \"Orilla del R√≠o\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "def get_sense_definition(word, sense_label):\n",
        "    synsets = wn.synsets(word, lang=\"spa\")\n",
        "\n",
        "    if not synsets:\n",
        "        return \"‚ö†Ô∏è No se encontr√≥ una definici√≥n en WordNet.\"\n",
        "\n",
        "    if sense_label == 0:\n",
        "        for syn in synsets:\n",
        "            if \"banco\" in syn.name() and \"financiera\" in syn.definition():\n",
        "                return syn.definition()\n",
        "\n",
        "    if sense_label == 1:\n",
        "        for syn in synsets:\n",
        "            if \"banco\" in syn.name() and \"r√≠o\" in syn.definition():\n",
        "                return syn.definition()\n",
        "\n",
        "    return synsets[0].definition()\n",
        "\n",
        "definition = get_sense_definition(\"banco\", pred[0])\n",
        "\n",
        "print(\"\\nüéØ Mejor sentido para la oraci√≥n de ejemplo:\")\n",
        "print(\"üîπ Sentido Predicho:\", predicted_sense)\n",
        "print(\"üìñ Definici√≥n:\", definition)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vq2GmnIVIhfK",
      "metadata": {
        "id": "vq2GmnIVIhfK"
      },
      "source": [
        "#Semi-supervised Methods (Bootstrapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "UKzRes97IoUz",
      "metadata": {
        "id": "UKzRes97IoUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d57435d-7867-4c31-f89b-443cdde66264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Initial Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "üåÄ Iteration 1 of Bootstrapping\n",
            "‚úÖ Added: 'The river bank was scenic and calm' ‚Üí Predicted as Financial Institution (Confidence: 0.85)\n",
            "üìà Retrained with 5 total samples.\n",
            "\n",
            "üåÄ Iteration 2 of Bootstrapping\n",
            "‚ö†Ô∏è No high-confidence samples to add. Stopping bootstrapping.\n",
            "\n",
            "üéØ Final Training Data Size: 5\n",
            "\n",
            "üéØ Best sense for example sentence:\n",
            "üîπ Predicted Sense: Financial Institution\n"
          ]
        }
      ],
      "source": [
        "labeled_data = [\n",
        "    (\"I deposited money at the bank\", 0),\n",
        "    (\"The bank approved my loan\", 0),\n",
        "    (\"The river bank was flooded\", 1),\n",
        "    (\"They had a picnic on the bank of the river\", 1)\n",
        "]\n",
        "\n",
        "unlabeled_texts = [\n",
        "    \"She went to the bank to open an account\",\n",
        "    \"We enjoyed the view by the bank\",\n",
        "    \"The bank offers great interest rates\",\n",
        "    \"The river bank was scenic and calm\"\n",
        "]\n",
        "\n",
        "labeled_texts, labels = zip(*labeled_data)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(labeled_texts, labels)\n",
        "\n",
        "y_pred = model.predict(labeled_texts)\n",
        "print(\"\\nüìä Initial Model Classification Report:\")\n",
        "print(classification_report(labels, y_pred))\n",
        "\n",
        "threshold = 0.8\n",
        "new_labeled_texts = list(labeled_texts)\n",
        "new_labels = list(labels)\n",
        "\n",
        "for iteration in range(3):\n",
        "    print(f\"\\nüåÄ Iteration {iteration+1} of Bootstrapping\")\n",
        "\n",
        "    predictions = model.predict_proba(unlabeled_texts)\n",
        "    to_add = []\n",
        "    remaining_texts = []\n",
        "\n",
        "    for text, probs in zip(unlabeled_texts, predictions):\n",
        "        max_prob = np.max(probs)\n",
        "        pred_label = np.argmax(probs)\n",
        "\n",
        "        if max_prob >= threshold:\n",
        "            to_add.append((text, pred_label))\n",
        "            print(f\"‚úÖ Added: '{text}' ‚Üí Predicted as {'Financial Institution' if pred_label==0 else 'River Bank'} (Confidence: {max_prob:.2f})\")\n",
        "        else:\n",
        "            remaining_texts.append(text)\n",
        "\n",
        "    if not to_add:\n",
        "        print(\"‚ö†Ô∏è No high-confidence samples to add. Stopping bootstrapping.\")\n",
        "        break\n",
        "\n",
        "    for text, label in to_add:\n",
        "        new_labeled_texts.append(text)\n",
        "        new_labels.append(label)\n",
        "\n",
        "    unlabeled_texts = remaining_texts\n",
        "    model.fit(new_labeled_texts, new_labels)\n",
        "    print(f\"üìà Retrained with {len(new_labeled_texts)} total samples.\")\n",
        "\n",
        "print(\"\\nüéØ Final Training Data Size:\", len(new_labeled_texts))\n",
        "\n",
        "example = [\"I need to visit the bank for a transaction\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Financial Institution\", 1: \"River Bank\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\nüéØ Best sense for example sentence:\")\n",
        "print(\"üîπ Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "iIhehulF8yCC"
      },
      "id": "iIhehulF8yCC"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "mhQBwRqgIouH",
      "metadata": {
        "id": "mhQBwRqgIouH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d78b5bd-54ae-4e30-a212-cf509e7128fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Informe de Clasificaci√≥n Inicial del Modelo:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "üåÄ Iteraci√≥n 1 de Bootstrapping\n",
            "‚úÖ A√±adido: 'El banco ofrece tasas de inter√©s atractivas' ‚Üí Predicho como Instituci√≥n Financiera (Confianza: 0.86)\n",
            "‚úÖ A√±adido: 'La orilla del r√≠o era hermosa y tranquila' ‚Üí Predicho como Orilla del R√≠o (Confianza: 0.87)\n",
            "üìà Reentrenado con 6 muestras en total.\n",
            "\n",
            "üåÄ Iteraci√≥n 2 de Bootstrapping\n",
            "‚ö†Ô∏è No hay muestras de alta confianza para agregar. Deteniendo el bootstrapping.\n",
            "\n",
            "üéØ Tama√±o final del conjunto de entrenamiento: 6\n",
            "\n",
            "üéØ Mejor sentido para la oraci√≥n de ejemplo:\n",
            "üîπ Sentido Predicho: Instituci√≥n Financiera\n"
          ]
        }
      ],
      "source": [
        "labeled_data = [\n",
        "    (\"Deposit√© dinero en el banco\", 0),\n",
        "    (\"El banco aprob√≥ mi pr√©stamo\", 0),\n",
        "    (\"La orilla del r√≠o estaba inundada\", 1),\n",
        "    (\"Hicieron un picnic en la orilla del r√≠o\", 1)\n",
        "]\n",
        "\n",
        "unlabeled_texts = [\n",
        "    \"Ella fue al banco para abrir una cuenta\",\n",
        "    \"Disfrutamos la vista junto al banco\",\n",
        "    \"El banco ofrece tasas de inter√©s atractivas\",\n",
        "    \"La orilla del r√≠o era hermosa y tranquila\"\n",
        "]\n",
        "\n",
        "labeled_texts, labels = zip(*labeled_data)\n",
        "model = make_pipeline(CountVectorizer(), SVC(kernel='linear', probability=True))\n",
        "model.fit(labeled_texts, labels)\n",
        "y_pred = model.predict(labeled_texts)\n",
        "print(\"\\nüìä Informe de Clasificaci√≥n Inicial del Modelo:\")\n",
        "print(classification_report(labels, y_pred))\n",
        "threshold = 0.8\n",
        "new_labeled_texts = list(labeled_texts)\n",
        "new_labels = list(labels)\n",
        "\n",
        "for iteration in range(3):\n",
        "    print(f\"\\nüåÄ Iteraci√≥n {iteration+1} de Bootstrapping\")\n",
        "\n",
        "    predictions = model.predict_proba(unlabeled_texts)\n",
        "    to_add = []\n",
        "    remaining_texts = []\n",
        "\n",
        "    for text, probs in zip(unlabeled_texts, predictions):\n",
        "        max_prob = np.max(probs)\n",
        "        pred_label = np.argmax(probs)\n",
        "\n",
        "        if max_prob >= threshold:\n",
        "            to_add.append((text, pred_label))\n",
        "            print(f\"‚úÖ A√±adido: '{text}' ‚Üí Predicho como {'Instituci√≥n Financiera' if pred_label==0 else 'Orilla del R√≠o'} (Confianza: {max_prob:.2f})\")\n",
        "        else:\n",
        "            remaining_texts.append(text)\n",
        "\n",
        "    if not to_add:\n",
        "        print(\"‚ö†Ô∏è No hay muestras de alta confianza para agregar. Deteniendo el bootstrapping.\")\n",
        "        break\n",
        "    for text, label in to_add:\n",
        "        new_labeled_texts.append(text)\n",
        "        new_labels.append(label)\n",
        "    unlabeled_texts = remaining_texts\n",
        "\n",
        "    model.fit(new_labeled_texts, new_labels)\n",
        "    print(f\"üìà Reentrenado con {len(new_labeled_texts)} muestras en total.\")\n",
        "\n",
        "print(\"\\nüéØ Tama√±o final del conjunto de entrenamiento:\", len(new_labeled_texts))\n",
        "\n",
        "example = [\"Necesito ir al banco para una transacci√≥n\"]\n",
        "pred = model.predict(example)\n",
        "\n",
        "sense_map = {0: \"Instituci√≥n Financiera\", 1: \"Orilla del R√≠o\"}\n",
        "predicted_sense = sense_map[pred[0]]\n",
        "\n",
        "print(\"\\nüéØ Mejor sentido para la oraci√≥n de ejemplo:\")\n",
        "print(\"üîπ Sentido Predicho:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0FvNNLcNItyu",
      "metadata": {
        "id": "0FvNNLcNItyu"
      },
      "source": [
        "#Unsupervised Methods (Clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-1 (English)"
      ],
      "metadata": {
        "id": "YQ9V_efG9Dxp"
      },
      "id": "YQ9V_efG9Dxp"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "-NAv26nnIuoX",
      "metadata": {
        "id": "-NAv26nnIuoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128ee7ad-5b3e-4cd2-a866-fba8993cdbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Clustering-based Word Sense Disambiguation:\n",
            "Cluster 0 (Financial Institution): I deposited money at the bank\n",
            "Cluster 0 (Financial Institution): The bank approved my loan\n",
            "Cluster 0 (Financial Institution): The river bank was flooded\n",
            "Cluster 0 (Financial Institution): They had a picnic on the bank of the river\n",
            "Cluster 1 (Financial Institution): She went to the bank to open an account\n",
            "Cluster 0 (Financial Institution): We enjoyed the view by the bank\n",
            "\n",
            "üéØ Best sense for example sentence:\n",
            "üîπ Predicted Sense: Financial Institution\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"I deposited money at the bank\",\n",
        "    \"The bank approved my loan\",\n",
        "    \"The river bank was flooded\",\n",
        "    \"They had a picnic on the bank of the river\",\n",
        "    \"She went to the bank to open an account\",\n",
        "    \"We enjoyed the view by the bank\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "num_clusters = 2\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "\n",
        "cluster_sense_map = {}\n",
        "for i in range(num_clusters):\n",
        "    representative_sentence = sentences[labels.tolist().index(i)]\n",
        "    if \"loan\" in representative_sentence or \"deposit\" in representative_sentence or \"account\" in representative_sentence:\n",
        "        cluster_sense_map[i] = \"Financial Institution\"\n",
        "    else:\n",
        "        cluster_sense_map[i] = \"River Bank\"\n",
        "\n",
        "print(\"\\nüîç Clustering-based Word Sense Disambiguation:\")\n",
        "for sentence, cluster in zip(sentences, labels):\n",
        "    print(f\"Cluster {cluster} ({cluster_sense_map[cluster]}): {sentence}\")\n",
        "\n",
        "example_sentence = [\"I need to visit the bank for a transaction\"]\n",
        "example_vector = vectorizer.transform(example_sentence)\n",
        "predicted_cluster = kmeans.predict(example_vector)[0]\n",
        "predicted_sense = cluster_sense_map[predicted_cluster]\n",
        "\n",
        "print(\"\\nüéØ Best sense for example sentence:\")\n",
        "print(\"üîπ Predicted Sense:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "eVr_y14O9CT7"
      },
      "id": "eVr_y14O9CT7"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ItWzHBMJIvA1",
      "metadata": {
        "id": "ItWzHBMJIvA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddedb6a-21ff-40ed-9427-dcc0d6944fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Desambiguaci√≥n de palabras basada en Clustering:\n",
            "Cluster 1 (Sail (Vela de Barco)): Encend√≠ una vela en la mesa\n",
            "Cluster 1 (Sail (Vela de Barco)): Apag√≥ la vela antes de dormir\n",
            "Cluster 0 (Sail (Vela de Barco)): El viento llen√≥ la vela del barco\n",
            "Cluster 1 (Sail (Vela de Barco)): El marinero ajust√≥ la vela para navegar mejor\n",
            "Cluster 1 (Sail (Vela de Barco)): Colocaron una vela en el pastel de cumplea√±os\n",
            "Cluster 1 (Sail (Vela de Barco)): La vela del velero era enorme\n",
            "\n",
            "üéØ Mejor sentido para la oraci√≥n de ejemplo:\n",
            "üîπ Sentido Predicho: Sail (Vela de Barco)\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"Encend√≠ una vela en la mesa\",\n",
        "    \"Apag√≥ la vela antes de dormir\",\n",
        "    \"El viento llen√≥ la vela del barco\",\n",
        "    \"El marinero ajust√≥ la vela para navegar mejor\",\n",
        "    \"Colocaron una vela en el pastel de cumplea√±os\",\n",
        "    \"La vela del velero era enorme\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=spanish_stopwords)\n",
        "X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "num_clusters = 2\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "cluster_sense_map = {}\n",
        "for i in range(num_clusters):\n",
        "    representative_sentence = sentences[labels.tolist().index(i)]\n",
        "    if \"encend√≠\" in representative_sentence or \"apag√≥\" in representative_sentence or \"pastel\" in representative_sentence:\n",
        "        cluster_sense_map[i] = \"Candle (Veladora)\"\n",
        "    else:\n",
        "        cluster_sense_map[i] = \"Sail (Vela de Barco)\"\n",
        "\n",
        "print(\"\\nüîç Desambiguaci√≥n de palabras basada en Clustering:\")\n",
        "for sentence, cluster in zip(sentences, labels):\n",
        "    print(f\"Cluster {cluster} ({cluster_sense_map[cluster]}): {sentence}\")\n",
        "\n",
        "example_sentence = [\"Puse una vela en la mesa para iluminar\"]\n",
        "example_vector = vectorizer.transform(example_sentence)\n",
        "predicted_cluster = kmeans.predict(example_vector)[0]\n",
        "predicted_sense = cluster_sense_map[predicted_cluster]\n",
        "\n",
        "print(\"\\nüéØ Mejor sentido para la oraci√≥n de ejemplo:\")\n",
        "print(\"üîπ Sentido Predicho:\", predicted_sense)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8662fa",
      "metadata": {
        "id": "3f8662fa"
      },
      "source": [
        "\n",
        "## Method-5: Enhanced Lesk Algorithm (Extended Lesk)\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "661804cd",
      "metadata": {
        "id": "661804cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5237ca-5607-4ee8-b6bf-5ee97f37fd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Lesk - Best sense: Synset('depository_financial_institution.n.01')\n",
            "Definition: a financial institution that accepts deposits and channels the money into lending activities\n"
          ]
        }
      ],
      "source": [
        "def enhanced_lesk(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "\n",
        "    for sense in wn.synsets(ambiguous_word):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        for ex in sense.examples():\n",
        "            signature.update(word_tokenize(ex))\n",
        "        for lemma in sense.lemmas():\n",
        "            signature.add(lemma.name())\n",
        "\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"I went to the bank to deposit my money\"\n",
        "ambiguous = \"bank\"\n",
        "sense = enhanced_lesk(sentence, ambiguous)\n",
        "print(\"Enhanced Lesk - Best sense:\", sense)\n",
        "print(\"Definition:\", sense.definition())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "fUBzoCZb9ccd"
      },
      "id": "fUBzoCZb9ccd"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "U6cvLugBI1g5",
      "metadata": {
        "id": "U6cvLugBI1g5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451ca801-8d84-4f22-d5e8-1733bd7585c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced Lesk - Mejor sentido: Synset('sierra.n.01')\n",
            "Definici√≥n: a range of mountains (usually with jagged peaks and irregular outline)\n"
          ]
        }
      ],
      "source": [
        "def enhanced_lesk_spanish(context_sentence, ambiguous_word):\n",
        "    context = set(word_tokenize(context_sentence))\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "    for sense in wn.synsets(ambiguous_word, lang=\"spa\"):\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        for ex in sense.examples():\n",
        "            signature.update(word_tokenize(ex))\n",
        "        for lemma in sense.lemmas():\n",
        "            signature.add(lemma.name())\n",
        "        overlap = len(context.intersection(signature))\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "    return best_sense\n",
        "\n",
        "sentence = \"Us√© la sierra para cortar la madera\"\n",
        "ambiguous = \"sierra\"\n",
        "sense = enhanced_lesk_spanish(sentence, ambiguous)\n",
        "print(\"Enhanced Lesk - Mejor sentido:\", sense)\n",
        "if sense:\n",
        "    print(\"Definici√≥n:\", sense.definition())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No se encontr√≥ una definici√≥n.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5df535f",
      "metadata": {
        "id": "a5df535f"
      },
      "source": [
        "\n",
        "## Method-6: Word Embeddings Based WSD\n",
        "\n",
        "### Block-1 (English)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f462cc36",
      "metadata": {
        "id": "f462cc36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2a9c1b-95f7-4df9-c542-1bbd29b589dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings WSD - Best Sense: Synset('bark.n.02')\n",
            "Definition: a noise resembling the bark of a dog\n"
          ]
        }
      ],
      "source": [
        "def get_signature_text_english(sense):\n",
        "    text = sense.definition() + \" \" + \" \".join(sense.examples()) + \" \" + \" \".join([lemma.name() for lemma in sense.lemmas()])\n",
        "    return text\n",
        "\n",
        "def embeddings_wsd_english(context_sentence, ambiguous_word):\n",
        "    senses = wn.synsets(ambiguous_word)\n",
        "    if not senses:\n",
        "        return None\n",
        "\n",
        "    corpus = [context_sentence] + [get_signature_text_english(sense) for sense in senses]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    context_vector = vectors[0]\n",
        "    sense_vectors = vectors[1:]\n",
        "\n",
        "    similarities = cosine_similarity(context_vector, sense_vectors)[0]\n",
        "    best_sense_index = similarities.argmax()\n",
        "    return senses[best_sense_index]\n",
        "\n",
        "sentence = \"The dog started to bark loudly\"\n",
        "ambiguous = \"bark\"\n",
        "sense = embeddings_wsd_english(sentence, ambiguous)\n",
        "\n",
        "print(\"Embeddings WSD - Best Sense:\", sense)\n",
        "print(\"Definition:\", sense.definition() if sense else \"‚ö†Ô∏è No definition found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block-2 (Spanish)"
      ],
      "metadata": {
        "id": "CpcqxB4u9iEq"
      },
      "id": "CpcqxB4u9iEq"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Ud7L_8McI5Kr",
      "metadata": {
        "id": "Ud7L_8McI5Kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9d7d42-cdfa-4a83-a45a-87bd95c2794b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings WSD - Mejor sentido: Synset('vigil.n.02')\n",
            "Definici√≥n: the rite of staying awake for devotional purposes (especially on the eve of a religious festival)\n"
          ]
        }
      ],
      "source": [
        "def get_signature_text_spanish(sense):\n",
        "    text = sense.definition() + \" \" + \" \".join(sense.examples()) + \" \" + \" \".join([lemma.name() for lemma in sense.lemmas()])\n",
        "    return text\n",
        "\n",
        "def embeddings_wsd_spanish(context_sentence, ambiguous_word):\n",
        "    senses = wn.synsets(ambiguous_word, lang=\"spa\")\n",
        "    if not senses:\n",
        "        return None\n",
        "\n",
        "    corpus = [context_sentence] + [get_signature_text_spanish(sense) for sense in senses]\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    context_vector = vectors[0]\n",
        "    sense_vectors = vectors[1:]\n",
        "\n",
        "    similarities = cosine_similarity(context_vector, sense_vectors)[0]\n",
        "    best_sense_index = similarities.argmax()\n",
        "    return senses[best_sense_index]\n",
        "\n",
        "sentence = \"Encend√≠ una vela en la mesa\"\n",
        "ambiguous = \"vela\"\n",
        "sense = embeddings_wsd_spanish(sentence, ambiguous)\n",
        "\n",
        "print(\"Embeddings WSD - Mejor sentido:\", sense)\n",
        "print(\"Definici√≥n:\", sense.definition() if sense else \"‚ö†Ô∏è No se encontr√≥ una definici√≥n.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "Word Sense Disambiguation (WSD) is a crucial task in Natural Language Processing (NLP) that helps determine the correct meaning of an ambiguous word based on its context. In this discussion, we explored multiple approaches to WSD, including supervised, semi-supervised, and unsupervised methods. The Lesk algorithm and its enhanced versions leveraged word definitions and context overlap, while the supervised approach used machine learning models like Support Vector Machines (SVMs) trained on labeled datasets. We also implemented semi-supervised bootstrapping, which expanded the training set by incorporating high-confidence predictions. The unsupervised clustering method applied TF-IDF vectorization and K-Means to group sentences based on similar meanings, offering a purely data-driven approach. Additionally, we experimented with word embeddings-based WSD using cosine similarity to compare contextual and definition vectors without relying on labeled data. Each method has its strengths‚Äîrule-based approaches are interpretable but limited by dictionary coverage, supervised methods perform well with sufficient labeled data, and unsupervised techniques offer scalability but may require fine-tuning. Our final consolidated setup ensures that all necessary libraries and datasets are available for seamless execution of any WSD method. These techniques collectively contribute to improving machine understanding of ambiguous words, which is essential for applications like machine translation, information retrieval, and text analysis."
      ],
      "metadata": {
        "id": "Bn4M7-9y9rNA"
      },
      "id": "Bn4M7-9y9rNA"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}