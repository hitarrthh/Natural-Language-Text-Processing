{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install word2number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0P6ZZA8BYiD",
        "outputId": "a2fdfe01-36ef-4973-a5d9-857d953de274"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCWPlvzVBMe7",
        "outputId": "8b4f8bb9-e6de-475b-a6ca-98e4e6c892a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.corpus import words\n",
        "from word2number import w2n\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I have 2 cars. The first car is a 2020 Toyota, and the second is a 2015 Honda. It is an amazing experience.\"\n",
        "print(\"CORPUS: \\n\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6KbgDbgBR4s",
        "outputId": "80b6ae40-a749-43bd-fc9c-be470437ac3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORPUS: \n",
            " I have 2 cars. The first car is a 2020 Toyota, and the second is a 2015 Honda. It is an amazing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "O5KdxbW1B_y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiMb0pc-B8oo",
        "outputId": "2a1f2a4f-3171-45ac-d089-9d92a47ce286"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['I', 'have', '2', 'cars', '.', 'The', 'first', 'car', 'is', 'a', '2020', 'Toyota', ',', 'and', 'the', 'second', 'is', 'a', '2015', 'Honda', '.', 'It', 'is', 'an', 'amazing', 'experience', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting Text to Lower Case"
      ],
      "metadata": {
        "id": "fKFCKV3BCKng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_case_text = text.lower()\n",
        "print(\"\\nLower Case Text:\", lower_case_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LQLJag1CDjn",
        "outputId": "18b2a21e-a6c7-443c-e9d2-3226f6b888aa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lower Case Text: i have 2 cars. the first car is a 2020 toyota, and the second is a 2015 honda. it is an amazing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Numbers"
      ],
      "metadata": {
        "id": "FgfIdLs3CRfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_no_numbers = re.sub(r'\\d+', '', text)\n",
        "print(\"\\nText without Numbers:\", text_no_numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_nbCsopCLg1",
        "outputId": "abc98d83-2eb0-4bdc-aaa4-ae262db67161"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text without Numbers: I have  cars. The first car is a  Toyota, and the second is a  Honda. It is an amazing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert Numbers to Words"
      ],
      "metadata": {
        "id": "kZv091xpCZRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_numbers_to_words(text):\n",
        "    words_in_text = text.split()\n",
        "    converted_text = []\n",
        "\n",
        "    for word in words_in_text:\n",
        "        try:\n",
        "            # Check if the word is a number and convert it to words\n",
        "            number = w2n.word_to_num(word)\n",
        "            converted_text.append(str(number))\n",
        "        except ValueError:\n",
        "            converted_text.append(word)\n",
        "\n",
        "    return ' '.join(converted_text)\n",
        "\n",
        "text_with_numbers_in_words = convert_numbers_to_words(text)\n",
        "print(\"\\nText with Numbers Converted to Words:\", text_with_numbers_in_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRqfu-a3CSEt",
        "outputId": "bb3b13bf-8c70-48ae-b95e-4e512e3e0f1a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text with Numbers Converted to Words: I have 2 cars. The first car is a 2020 Toyota, and the second is a 2015 Honda. It is an amazing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Punctuation"
      ],
      "metadata": {
        "id": "wl9B_1L0CfR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_no_punctuation = re.sub(r'[^\\w\\s]', '', text)\n",
        "print(\"\\nText without Punctuation:\", text_no_punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHTKPXCrCaGT",
        "outputId": "37dc2e4f-23b5-4661-82ae-c34f219cbf59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text without Punctuation: I have 2 cars The first car is a 2020 Toyota and the second is a 2015 Honda It is an amazing experience\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Whitespace"
      ],
      "metadata": {
        "id": "4IWKB1c1ClUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_no_whitespace = ' '.join(text.split())\n",
        "print(\"\\nText without Extra Whitespace:\", text_no_whitespace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmaP8e9YCgC7",
        "outputId": "a92f5d0e-a19e-4ef8-d9f8-ff3296b631c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text without Extra Whitespace: I have 2 cars. The first car is a 2020 Toyota, and the second is a 2015 Honda. It is an amazing experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove Stop Words"
      ],
      "metadata": {
        "id": "GKGZIdSXC3yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "tokens_without_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(\"\\nTokens without Stop Words:\", tokens_without_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5D-KpsACmUc",
        "outputId": "2156d1a6-bb7e-4b69-dfc6-27e6633e5f8d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokens without Stop Words: ['2', 'cars', '.', 'first', 'car', '2020', 'Toyota', ',', 'second', '2015', 'Honda', '.', 'amazing', 'experience', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count Word Frequency"
      ],
      "metadata": {
        "id": "11DuUv1gC_g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_frequency = Counter(tokens_without_stopwords)\n",
        "print(\"\\nWord Frequency:\", word_frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoxC6JQoC3Ii",
        "outputId": "507e72c3-dafa-4c05-8ee1-9df182a3c25f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Frequency: Counter({'.': 3, '2': 1, 'cars': 1, 'first': 1, 'car': 1, '2020': 1, 'Toyota': 1, ',': 1, 'second': 1, '2015': 1, 'Honda': 1, 'amazing': 1, 'experience': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming (Porter and Lancaster Stemmer)"
      ],
      "metadata": {
        "id": "AUtgH3sBDFw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "porter_stems = [porter_stemmer.stem(word) for word in tokens]\n",
        "lancaster_stems = [lancaster_stemmer.stem(word) for word in tokens]\n",
        "\n",
        "print(\"\\nPorter Stemmer Stems:\", porter_stems)\n",
        "print(\"\\nLancaster Stemmer Stems:\", lancaster_stems)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSEhMxXWC9CS",
        "outputId": "68cee184-e58d-41db-b634-2dcb73819403"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Porter Stemmer Stems: ['i', 'have', '2', 'car', '.', 'the', 'first', 'car', 'is', 'a', '2020', 'toyota', ',', 'and', 'the', 'second', 'is', 'a', '2015', 'honda', '.', 'it', 'is', 'an', 'amaz', 'experi', '.']\n",
            "\n",
            "Lancaster Stemmer Stems: ['i', 'hav', '2', 'car', '.', 'the', 'first', 'car', 'is', 'a', '2020', 'toyot', ',', 'and', 'the', 'second', 'is', 'a', '2015', 'hond', '.', 'it', 'is', 'an', 'amaz', 'expery', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "F2AAIeSGDO-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(\"\\nLemmatized Tokens:\", lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "640IBJKpDDDJ",
        "outputId": "2044de3a-63b6-4c06-e99c-0882382b28e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lemmatized Tokens: ['I', 'have', '2', 'car', '.', 'The', 'first', 'car', 'is', 'a', '2020', 'Toyota', ',', 'and', 'the', 'second', 'is', 'a', '2015', 'Honda', '.', 'It', 'is', 'an', 'amazing', 'experience', '.']\n"
          ]
        }
      ]
    }
  ]
}